{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark_DataProcessing_Example.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPIuYFmeBs7c4rlgP5Sd7Kh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fitriindra/BigDataCourseExamples/blob/master/PySpark_DataProcessing_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGdm387Z1yt7",
        "colab_type": "text"
      },
      "source": [
        "# **Contoh pemrosesan data menggunakan RDD pada Dataset Titanic**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4pW7Q1O17Qu",
        "colab_type": "text"
      },
      "source": [
        "# **1. Instalasi Spark pada Google Colab**\n",
        "kode di bawah ini hanya dijalankan **satu kali saja** saat runtime pertama kali dijalankan.\n",
        "\n",
        "Sebelum menjalankan, uncomment baris-baris kode di bawah ini"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0bguDJG17oU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-eu.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voyijIsm2BAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sd5TT_Y2b1y",
        "colab_type": "text"
      },
      "source": [
        "# **2. Import library Spark yang sudah diinstal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lHHgKVM2bfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init(\"spark-2.4.5-bin-hadoop2.7\")# SPARK_HOME\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "from pyspark.sql.functions import col, avg"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2bzxEB85Oqa",
        "colab_type": "text"
      },
      "source": [
        "# **3. Inisialisasi SparkContext dan SparkSession**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SboRBZux5LTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc = spark.sparkContext\n",
        "spark = SparkSession(sc)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L55Cj--c5cbj",
        "colab_type": "text"
      },
      "source": [
        "# **4. Load Dataset**\n",
        "\n",
        "Pada langkah ini, dataset berupa file CSV di-load. Dataset merupakan data yang sudah dilakukan proses pre-processing (lihat contoh [```PySpark EDA Example```](https://colab.research.google.com/drive/1NQth__UYjDBOG-b-RsvY56siYdGGn8r0?usp=sharing)).\n",
        "Lokasi file csv sama dengan lokasi file kode program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xcGSNT85dZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "ccc9157e-59c8-4ee3-d3d3-d69eb954c679"
      },
      "source": [
        "titanic_df = spark.read.csv(\"titanic_processed.csv\", header=True, inferSchema=True)\n",
        "titanic_df.printSchema()            #mengecek schema dari dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- PassengerId: integer (nullable = true)\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Cabin: string (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErOb80jY9-Vm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a5e9d93a-357c-4ffa-89a8-5fbadce0715e"
      },
      "source": [
        "titanic_df.show(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|          1|       0|     3|Braund Mr. Owen H...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
            "|          2|       1|     1|Cumings Mrs. John...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
            "|          3|       1|     3|Heikkinen Miss. L...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
            "|          4|       1|     1|Futrelle Mrs. Jac...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
            "|          5|       0|     3|Allen Mr. William...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
            "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E9d0eP16NZt",
        "colab_type": "text"
      },
      "source": [
        "# **5. Pemrosesan Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIDHCYIQAHYQ",
        "colab_type": "text"
      },
      "source": [
        "## 5.1 Pemrosesan Menggunakan Transformasi dan Action pada DataFrame\n",
        "\n",
        "Contoh pemrosesan:\n",
        "\n",
        "Menghitung rata-rata umur penumpang yang selamat berdasarkan jenis kelamin.\n",
        "\n",
        "Langkahnya adalah:\n",
        "1.   Melakukan filter terhadap kolom Survived. Data dengan nilai ```Survived = 1``` berarti penumpang selamat. Data dengan filter ```Survived = 1``` inilah yang akan dipakai pada proses berikutnya\n",
        "2.   Melakukan perhitungan rata-rata umur. Perhitungan dilakukan dengan melakukan grouping berdasarkan jenis kelamin kemudian dihitung rata-rata per jenis kelamin. Proses ini dapat digabung menjadi satu baris kode (lihat di bawah)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8co-_3TF6GgW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "58f524e6-2f31-4ffd-8798-1c7977f78aee"
      },
      "source": [
        "#filter kolom Survived yang nilainya 1 (selamat)\n",
        "titanic_survived = titanic_df.filter(titanic_df.Survived == 1)\n",
        "#jumlah total penumpang selamat\n",
        "print(\"jumlah penumpang selamat:\", titanic_survived.count())\n",
        "#perhitungan rata-rata penumpang berdasarkan jenis kelamin\n",
        "titanic_survived.groupby(\"Sex\").avg(\"Age\").show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jumlah penumpang selamat: 342\n",
            "+------+------------------+\n",
            "|   Sex|          avg(Age)|\n",
            "+------+------------------+\n",
            "|female|28.979262812421116|\n",
            "|  male| 27.63170534268753|\n",
            "+------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXCS3MKIAC2o",
        "colab_type": "text"
      },
      "source": [
        "## 5.2 Pemrosesan Menggunakan SparkSQL\n",
        "\n",
        "Contoh pemrosesan:\n",
        "\n",
        "Contoh studi kasus \"Menghitung rata-rata umur penumpang yang selamat berdasarkan jenis kelamin\" dapat dikerjakan menggunakan beberapa cara, menggunakan fungsi transformations dan actions pada RDD yang telah dikerjakan di 5.1 atau menggunakan DataFrame dan SparkSQL.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l1dkQ6QAf9i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0e2cd38d-e5eb-4681-9b61-3ffbe48feebe"
      },
      "source": [
        "#membuat table (view)\n",
        "titanic_survived.createOrReplaceTempView(\"titanic\")\n",
        "\n",
        "#menggunakan PySparkSQL untuk mencari rata-rata penumpang selamat berdasarkan jenis kelamin\n",
        "df_result = spark.sql(\"SELECT Sex, AVG(Age) FROM titanic WHERE Survived = 1 GROUP BY Sex\")\n",
        "df_result.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+------------------+\n",
            "|   Sex|          avg(Age)|\n",
            "+------+------------------+\n",
            "|female|28.979262812421116|\n",
            "|  male| 27.63170534268753|\n",
            "+------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BegoyxvCTIl",
        "colab_type": "text"
      },
      "source": [
        "hasil menggunakan transformations dan actions pada langkah 5.1 sama dengan hasil menggunakan PySparkSQL pada langkah 5.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAlOwLa25ml9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark.stop()    #digunakan untuk menghentikan SparkSession"
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}